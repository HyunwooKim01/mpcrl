# q_learning_real.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Real-sensor Q-learning for RL-MPC (no simulator).
#   - Sensor/Disturbance via MQTT (real_env.py)
#   - CasADi MPC policy (learning_real_detail.py: LearningMpcCasADi)
#   - Reward: env.compute_reward (paper Eqs. (18)â€“(21) structure)
#   - Î¸ = {Q, R, S, alpha_growth} online update (paper Eq. (22) style)
#   - Auto-save Î¸ every 6 hours to trained_theta.pkl and hot-reload
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations
import os, sys, time, json, math, pickle, signal, argparse
from dataclasses import dataclass
from typing import Dict, List, Tuple
import numpy as np

# â”€â”€ Project modules
from real_env import RealEnvironment
try:
    # ë„ˆê°€ ì˜¬ë¦° í•™ìŠµìš© MPC í´ë˜ìŠ¤ (CasADi ê¸°ë°˜)
    from learning_real_detail import LearningMpcCasADi
except Exception as e:
    print(f"[FATAL] learning_real_detail import ì‹¤íŒ¨: {e}")
    sys.exit(1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_THETA_PATH = "trained_theta.pkl"

@dataclass
class HyperParams:
    gamma: float = 0.99          # discount (TDí˜• ê·¼ì‚¬ì—ì„œ ì‚¬ìš©)
    lr_q: float = 1e-3           # Q ê°€ì¤‘ ì—…ë°ì´íŠ¸ í•™ìŠµë¥ 
    lr_r: float = 1e-3           # R ê°€ì¤‘ ì—…ë°ì´íŠ¸ í•™ìŠµë¥ 
    lr_s: float = 2e-3           # S ê°€ì¤‘ ì—…ë°ì´íŠ¸ í•™ìŠµë¥  (ì œì•½ ìœ„ë°˜ì— ë” ë¯¼ê°)
    lr_alpha: float = 2e-3       # ì„±ì¥ ê°€ì¤‘ ì—…ë°ì´íŠ¸ í•™ìŠµë¥ 
    clip_step: float = 0.05      # ê°€ì¤‘ í•œ ìŠ¤í… ë³€í™”ìœ¨ í´ë¦½(Â±5%)
    save_interval_s: int = 6*3600  # 6ì‹œê°„ë§ˆë‹¤ ì €ì¥
    horizon_N: int = 24          # MPC horizon (â‰ˆ 6h if 15min, ë˜ëŠ” ì‹¤ê³„ì¸¡ ì£¼ê¸°ì— ë§ì¶¤)
    warmup_steps: int = 5        # ì´ˆê¸° ê³¼ë„ ìŠ¤í… (du í° ì˜í–¥ ë°©ì§€)
    max_q: float = 1e3           # ì•ˆì •ìš© ìƒí•œ
    max_r: float = 1e2
    max_s: float = 1e3
    alpha_bounds: Tuple[float,float] = (0.1, 10.0)

HP = HyperParams()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Î¸ ë¡œë“œ/ì €ì¥ & MPC ë°˜ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_theta(path: str) -> Dict:
    if not os.path.exists(path):
        # ê¸°ë³¸ê°’: ì˜¨ë„/ìŠµë„ ì¶”ì ì€ ë†’ê²Œ, Î”u/ì—ë„ˆì§€ëŠ” ë³´í†µ, ì œì•½ ìœ„ë°˜ì€ ê°•í•˜ê²Œ
        return {
            "Q": [2.0, 2.0, 0.0, 0.0],      # [temp, hum, co2, light] ì¶”ì  ê°€ì¤‘(í•„ìš”ì‹œ í™•ì¥)
            "R": [0.05, 0.05, 0.02],        # [fan, heater, led] ì œì–´ ê°€ì¤‘
            "S": [5.0, 5.0],                # [temp_violation, hum_violation]
            "alpha_growth": 1.0,            # ì„±ì¥ ë³´ìƒ ê°€ì¤‘
        }
    with open(path, "rb") as f:
        return pickle.load(f)

def save_theta(theta: Dict, path: str = DEFAULT_THETA_PATH):
    tmp = path + ".tmp"
    with open(tmp, "wb") as f:
        pickle.dump(theta, f)
    os.replace(tmp, path)
    print(f"ğŸ’¾ Î¸ saved â†’ {path}")

def apply_theta_to_mpc(mpc: LearningMpcCasADi, theta: Dict):
    """mpc ë‚´ë¶€ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬/ìŠ¤ì¹¼ë¼ë¥¼ Î¸ë¡œ ê°±ì‹ . (í•™ìŠµ í´ë˜ìŠ¤ ì¸í„°í˜ì´ìŠ¤ì— ë§ì¶° ì ìš©)"""
    try:
        # Q, R, Sê°€ np.diagë¡œ ì •ì˜ë˜ì–´ ìˆë‹¤ëŠ” ê°€ì •(ë„ˆì˜ í•™ìŠµ í´ë˜ìŠ¤ê°€ ì´ í˜•íƒœ)
        Qd = np.array(theta.get("Q", []), dtype=float)
        Rd = np.array(theta.get("R", []), dtype=float)
        Sd = np.array(theta.get("S", []), dtype=float)

        if Qd.size > 0:
            mpc.Q = np.diag(Qd)
        if Rd.size > 0:
            mpc.R = np.diag(Rd)
        if Sd.size > 0:
            # temp/hum ìœ„ë°˜ ìŠ¬ë™ ê°€ì¤‘ì¹˜ë§Œ ë°˜ì˜ (í•„ìš”ì‹œ í™•ì¥)
            mpc.S = np.diag(Sd)

        if "alpha_growth" in theta:
            mpc.alpha_growth = float(theta["alpha_growth"])

        # í˜¹ì‹œ í´ë˜ìŠ¤ì— ì œê³µë˜ëŠ” í¸ì˜í•¨ìˆ˜ê°€ ìˆë‹¤ë©´ ì‚¬ìš©
        if hasattr(mpc, "on_theta_updated"):
            mpc.on_theta_updated()

    except Exception as e:
        print(f"[WARN] apply_theta_to_mpc ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë³´ì¡°: ì§€í‘œ ì¶”ì •(ì‹¤ì¸¡ ê¸°ë°˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def estimate_terms(x: np.ndarray,
                   x_ref_ranges: Dict,
                   u: np.ndarray,
                   u_prev: np.ndarray) -> Dict[str, float]:
    """
    ë…¼ë¬¸ ì‹ (18)â€“(21) í•­ë“¤ì„ í˜„ì‹¤ì ìœ¼ë¡œ ê·¼ì‚¬í•´ì„œ ìŠ¤ì¹¼ë¼ ì§€í‘œë¡œ ìš”ì•½.
    - ì¶”ì ì˜¤ì°¨: ì˜¨ë„/ìŠµë„ ì¤‘ì‹¬ê°’ ê¸°ì¤€ ì œê³±ì˜¤ì°¨
    - ì œì•½ìœ„ë°˜: ë²”ìœ„ ë„˜ì–´ì„  ì´ëŸ‰(ì œê³± ëˆ„ì )
    - ì—ë„ˆì§€: fan/heater ì œê³±í•©
    - Î”u: ì œì–´ ë³€í™”ìœ¨ ì œê³±í•©
    - ì„±ì¥: T/H/Lì˜ ê°„ë‹¨í•œ ê°€ìš°ì‹œì•ˆ/í¬í™” ê·¼ì‚¬(= real_env.compute_rewardì™€ ì¼ì¹˜í•˜ê²Œ)
    """
    temp, hum, co2, light = [float(v) for v in x]
    Tmin, Tmax = x_ref_ranges.get("target_temp", [18.0, 22.0])
    Hmin, Hmax = x_ref_ranges.get("target_humidity", [50.0, 70.0])
    Tref = 0.5*(Tmin+Tmax); Href = 0.5*(Hmin+Hmax)

    err_T = (temp - Tref)**2
    err_H = (hum  - Href)**2
    viol_T = max(0.0, Tmin-temp) + max(0.0, temp-Tmax)
    viol_H = max(0.0, Hmin-hum ) + max(0.0, hum -Hmax)
    viol = viol_T**2 + viol_H**2

    fan, heater, led = [float(np.clip(v,0,1)) for v in u]
    energy = fan**2 + heater**2
    du = u - u_prev
    du2 = float(np.sum(du*du))

    G_temp = math.exp(-0.5 * ((temp - 25.0) / 2.5) ** 2)
    G_hum  = math.exp(-0.5 * ((hum  - 60.0) / 8.0)  ** 2)
    G_light = math.tanh(light / 500.0)
    growth = G_temp * G_hum * G_light

    return dict(err_T=err_T, err_H=err_H, viol=viol, energy=energy, du2=du2, growth=growth)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ê·œì¹™ (Q-learning style heuristic)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def update_theta(theta: Dict, terms: Dict[str,float]):
    """
    ë…¼ë¬¸ (22)ì˜ íŒŒë¼ë¯¸í„°í™”ëœ MPC ë¹„ìš©ì„ í˜„ì‹¤ì ìœ¼ë¡œ ê·¼ì‚¬:
      - Q: ì¶”ì ì˜¤ì°¨(err_T, err_H)ê°€ í¬ë©´ ì¦ê°€, ì‘ìœ¼ë©´ ì™„ë§Œíˆ ê°ì†Œ
      - S: ì œì•½ìœ„ë°˜(viol)ì´ í¬ë©´ ê°•í•˜ê²Œ ì¦ê°€
      - R: Î”u/ì—ë„ˆì§€ í¬ë©´ ì¦ê°€
      - alpha_growth: growthê°€ í´ìˆ˜ë¡ ì¡°ê¸ˆ ì¦ê°€(ì„±ì¥ì— ë³´ìƒ), ìœ„ë°˜ í¬ë©´ ê°ì†Œ(ì•ˆì „ ìš°ì„ )
    ì „ì²´ëŠ” ì‘ì€ í•™ìŠµë¥ ê³¼ ë³€í™”ìœ¨ í´ë¦½ìœ¼ë¡œ ì•ˆì •í™”.
    """
    Q = np.array(theta["Q"], dtype=float)       # [temp, hum, (co2), (light)]
    R = np.array(theta["R"], dtype=float)       # [fan, heater, led]
    S = np.array(theta["S"], dtype=float)       # [temp_slack, hum_slack]
    alpha = float(theta["alpha_growth"])

    # â€” ìŠ¤ì¼€ì¼ë§ (ì•ˆì •í™”ë¥¼ ìœ„í•œ ì‘ì€ ë¹„ìœ¨)
    dq_T =  (+HP.lr_q * terms["err_T"]) - (0.25*HP.lr_q * max(0.0, 0.02-terms["err_T"]))
    dq_H =  (+HP.lr_q * terms["err_H"]) - (0.25*HP.lr_q * max(0.0, 0.02-terms["err_H"]))
    dS   =  (+HP.lr_s * terms["viol"])
    dR   =  (+HP.lr_r * (0.6*terms["du2"] + 0.4*terms["energy"]))

    # â€” ì„±ì¥/ì•ˆì „ íŠ¸ë ˆì´ë“œì˜¤í”„
    dalpha =  (+HP.lr_alpha * (terms["growth"] - 0.2)) - (HP.lr_alpha * 0.1 * (terms["viol"]>0))

    # â€” ì ìš© (í´ë¦½ & ê²½ê³„)
    def step_clip(v, dv, vmax):
        delta = np.clip(dv, -HP.clip_step*max(1.0,abs(v)), HP.clip_step*max(1.0,abs(v)))
        return float(np.clip(v + delta, 0.0, vmax))

    # Q: tempâ†’0, humâ†’1 ì¸ë±ìŠ¤ ê°€ì •
    if Q.size >= 2:
        Q[0] = step_clip(Q[0], dq_T, HP.max_q)
        Q[1] = step_clip(Q[1], dq_H, HP.max_q)

    # S: temp/hum slack
    if S.size >= 2:
        S[0] = step_clip(S[0], dS, HP.max_s)
        S[1] = step_clip(S[1], dS, HP.max_s)

    # R: ëª¨ë“  ì…ë ¥ì— ë™ì¼ ì¦ë¶„(ë‹¨ìˆœí™”)
    for i in range(R.size):
        R[i] = step_clip(R[i], dR, HP.max_r)

    alpha = float(np.clip(alpha + dalpha, HP.alpha_bounds[0], HP.alpha_bounds[1]))

    theta["Q"] = Q.tolist()
    theta["R"] = R.tolist()
    theta["S"] = S.tolist()
    theta["alpha_growth"] = alpha

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë£¨í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--broker_host", type=str, default="172.27.148.207")
    ap.add_argument("--broker_port", type=int, default=1883)
    ap.add_argument("--farm_id", type=str, default="farmA")
    ap.add_argument("--esp_id", type=str, default="esp1")
    ap.add_argument("--sample_time", type=float, default=5.0)
    ap.add_argument("--theta_path", type=str, default=DEFAULT_THETA_PATH)
    ap.add_argument("--horizon", type=int, default=HP.horizon_N)
    args = ap.parse_args()

    # 1) Real env (MQTT)
    env = RealEnvironment(
        sample_time=args.sample_time,
        broker_host=args.broker_host,
        broker_port=args.broker_port,
        farm_id=args.farm_id,
        esp_id=args.esp_id,
    )

    # 2) MPC (CasADi)
    try:
        mpc = LearningMpcCasADi(ts=env.sample_time, N=args.horizon)
    except TypeError:
        # ì‹œê·¸ë‹ˆì²˜ê°€ ë‹¤ë¥´ë©´ í•©ë¦¬ì  ê¸°ë³¸ê°’ ì‚¬ìš©
        mpc = LearningMpcCasADi()

    # 3) Î¸ ë¡œë“œ & MPC ì ìš©
    theta = load_theta(args.theta_path)
    apply_theta_to_mpc(mpc, theta)
    # 3) Î¸ ë¡œë“œ & MPC ì ìš©
    theta = load_theta(args.theta_path)
    apply_theta_to_mpc(mpc, theta)
    # numpy ë°°ì—´ì´ ì„ì—¬ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì¶œë ¥
    theta_safe = {k: (v.tolist() if hasattr(v, "tolist") else v) for k, v in theta.items()}
    print("ğŸ”§ Î¸ loaded & applied:", json.dumps(theta_safe, indent=2, ensure_ascii=False))


    # 4) ë£¨í”„ ì¤€ë¹„
    u_prev = np.zeros(3, dtype=float)
    last_save = time.time()
    step = 0

    # ì•ˆì „í•œ ì¢…ë£Œ
    stop_flag = {"stop": False}
    def handle_sig(sig, frm):
        stop_flag["stop"] = True
        print("\nğŸ›‘ Stopping... (saving Î¸)")
    signal.signal(signal.SIGINT, handle_sig)
    signal.signal(signal.SIGTERM, handle_sig)

    # ì°¸ì¡° ë²”ìœ„(ë³´ìƒì— ì‚¬ìš©)
    crop = env.crop  # real_env ë‚´ë¶€ì—ì„œ ë¡œë“œë¨

    print("ğŸš€ Start real Q-learning loop (no simulator)")
    while not stop_flag["stop"]:
        try:
            # (1) í˜„ì¬ ìƒíƒœ
            x, d = env.read_sensors()
            s = np.concatenate([x, d])

            # (2) MPC policy (u_opt)
            u_opt, J_mpc = None, None
            try:
                # ë„¤ê°€ ë§Œë“  í´ë˜ìŠ¤ì— ë§ê²Œ policy ë°˜í™˜ê°’ ì‚¬ìš©
                # (u_opt, J) ë˜ëŠ” u_opt ë§Œ ë°˜í™˜ ê°€ëŠ¥ì„± ë‘˜ ë‹¤ ëŒ€ì‘
                out = mpc.policy(s)
                if isinstance(out, tuple) and len(out) >= 1:
                    u_opt = np.array(out[0], dtype=float).reshape(-1)
                    if len(out) >= 2:
                        J_mpc = float(out[1])
                else:
                    u_opt = np.array(out, dtype=float).reshape(-1)
            except Exception as e:
                print(f"[WARN] MPC policy ì‹¤íŒ¨: {e}")
                u_opt = np.zeros(3, dtype=float)

            # (3) ì•¡ì¶”ì—ì´í„° ì „ì†¡
            env.send_actuators(u_opt)

            # (4) ë‹¤ìŒ ìƒíƒœ ê´€ì¸¡
            time.sleep(env.sample_time)
            x_next, d_next = env.read_sensors()

            # (5) ë³´ìƒ
            r = env.compute_reward(x_next, u_opt, u_prev=u_prev, J_mpc=J_mpc)

            # (6) Î¸ ì—…ë°ì´íŠ¸ (ì›Œë°ì—… í›„)
            if step >= HP.warmup_steps:
                terms = estimate_terms(x_next, crop, u_opt, u_prev)
                update_theta(theta, terms)
                apply_theta_to_mpc(mpc, theta)

            u_prev = u_opt.copy()
            step += 1

            # (7) ì£¼ê¸° ì €ì¥ & í•« ë¦¬ë¡œë“œ(ì™¸ë¶€ì—ì„œ íŒŒì¼ì´ ê°±ì‹ ëœ ê²½ìš° ëŒ€ë¹„)
            now = time.time()
            if (now - last_save) >= HP.save_interval_s:
                save_theta(theta, args.theta_path)
                # ì™¸ë¶€ ê°±ì‹  ìš°ì„ ì‹œí•  ê²½ìš°: ìƒˆë¡œ ë¡œë“œí•˜ì—¬ í•©ì¹˜ê³ ì í•˜ë©´ ì£¼ì„ í•´ì œ
                # theta_ext = load_theta(args.theta_path)
                # theta = theta_ext
                last_save = now
                print("ğŸ§  Î¸ periodic update done.")

        except Exception as e:
            print(f"[LOOP WARN] {e}")
            time.sleep(min(10.0, env.sample_time*2))

    # ì¢…ë£Œ ì‹œ ì €ì¥
    save_theta(theta, args.theta_path)
    print("âœ… Exit cleanly.")

if __name__ == "__main__":
    main()
